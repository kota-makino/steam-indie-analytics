#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
åé›†ã•ã‚ŒãŸã‚²ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’ç›£è¦–ã—ã€ç•°å¸¸å€¤ã‚„æ¬ æãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºã™ã‚‹ã€‚
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any, Optional
from sqlalchemy import create_engine, text
from sqlalchemy.ext.asyncio import AsyncSession
import asyncio
import logging
import os
from dotenv import load_dotenv
from datetime import datetime, timedelta
from dataclasses import dataclass

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å‡¦ç†
try:
    from ..config.database import get_db_session
except ImportError:
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    try:
        from config.database import get_db_session
    except ImportError:
        get_db_session = None


@dataclass
class DataQualityReport:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆçµæœ"""
    table_name: str
    total_records: int
    quality_score: float
    issues_found: List[str]
    recommendations: List[str]
    check_timestamp: str


class DataQualityChecker:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.logger = logging.getLogger(__name__)
        load_dotenv()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š
        self.db_config = {
            "host": os.getenv("POSTGRES_HOST", "postgres"),
            "port": int(os.getenv("POSTGRES_PORT", 5432)),
            "database": os.getenv("POSTGRES_DB", "steam_analytics"),
            "user": os.getenv("POSTGRES_USER", "steam_user"),
            "password": os.getenv("POSTGRES_PASSWORD", "steam_password"),
        }
        
        # SQLAlchemy ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
        self.engine = create_engine(
            f"postgresql://{self.db_config['user']}:{self.db_config['password']}@"
            f"{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        )

    async def check_basic_data_quality_async(self, session: AsyncSession) -> Dict[str, Any]:
        """
        åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
        Returns:
            ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯çµæœ
        """
        try:
            quality_check_query = text("""
                SELECT 
                    COUNT(*) as total_games,
                    COUNT(CASE WHEN name IS NULL OR name = '' THEN 1 END) as missing_names,
                    COUNT(CASE WHEN genres IS NULL OR array_length(genres, 1) = 0 THEN 1 END) as missing_genres,
                    COUNT(CASE WHEN developers IS NULL OR array_length(developers, 1) = 0 THEN 1 END) as missing_developers,
                    COUNT(CASE WHEN price_final IS NULL THEN 1 END) as missing_prices,
                    COUNT(CASE WHEN price_final < 0 THEN 1 END) as negative_prices,
                    COUNT(CASE WHEN price_final > 10000 THEN 1 END) as extreme_prices,
                    COUNT(CASE WHEN positive_reviews IS NULL THEN 1 END) as missing_positive_reviews,
                    COUNT(CASE WHEN negative_reviews IS NULL THEN 1 END) as missing_negative_reviews,
                    COUNT(CASE WHEN positive_reviews < 0 OR negative_reviews < 0 THEN 1 END) as negative_reviews_count,
                    COUNT(CASE WHEN created_at IS NULL THEN 1 END) as missing_timestamps,
                    COUNT(DISTINCT app_id) as unique_app_ids,
                    AVG(CASE WHEN price_final > 0 THEN price_final/100.0 ELSE NULL END) as avg_price,
                    STDDEV(CASE WHEN price_final > 0 THEN price_final/100.0 ELSE NULL END) as price_stddev
                FROM games 
                WHERE type = 'game';
            """)
            
            result = await session.execute(quality_check_query)
            quality_data = dict(result.fetchone()._mapping)
            
            # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
            total_games = quality_data['total_games']
            
            if total_games == 0:
                quality_score = 0.0
                issues = ["ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“"]
            else:
                # å„å“è³ªæŒ‡æ¨™ã®è¨ˆç®—
                name_completeness = 1 - (quality_data['missing_names'] / total_games)
                genre_completeness = 1 - (quality_data['missing_genres'] / total_games)
                developer_completeness = 1 - (quality_data['missing_developers'] / total_games)
                price_validity = 1 - (quality_data['negative_prices'] + quality_data['extreme_prices']) / total_games
                review_completeness = 1 - (quality_data['missing_positive_reviews'] + quality_data['missing_negative_reviews']) / (total_games * 2)
                uniqueness = quality_data['unique_app_ids'] / total_games
                
                # ç·åˆå“è³ªã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
                quality_score = (name_completeness + genre_completeness + developer_completeness + 
                               price_validity + review_completeness + uniqueness) / 6 * 100
                
                # å•é¡Œæ¤œå‡º
                issues = []
                if quality_data['missing_names'] > 0:
                    issues.append(f"ã‚²ãƒ¼ãƒ åæ¬ æ: {quality_data['missing_names']}ä»¶")
                if quality_data['missing_genres'] > 0:
                    issues.append(f"ã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±æ¬ æ: {quality_data['missing_genres']}ä»¶")
                if quality_data['missing_developers'] > 0:
                    issues.append(f"é–‹ç™ºè€…æƒ…å ±æ¬ æ: {quality_data['missing_developers']}ä»¶")
                if quality_data['negative_prices'] > 0:
                    issues.append(f"è² ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿: {quality_data['negative_prices']}ä»¶")
                if quality_data['extreme_prices'] > 0:
                    issues.append(f"ç•°å¸¸é«˜é¡ä¾¡æ ¼ï¼ˆ$100è¶…ï¼‰: {quality_data['extreme_prices']}ä»¶")
                if quality_data['negative_reviews_count'] > 0:
                    issues.append(f"è² ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {quality_data['negative_reviews_count']}ä»¶")
            
            return {
                'quality_metrics': quality_data,
                'quality_score': round(quality_score, 1),
                'issues_found': issues,
                'check_timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def check_data_distribution_async(self, session: AsyncSession) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒãƒã‚§ãƒƒã‚¯ï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
        Returns:
            ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒåˆ†æçµæœ
        """
        try:
            distribution_query = text("""
                WITH price_stats AS (
                    SELECT 
                        MIN(price_final/100.0) as min_price,
                        MAX(price_final/100.0) as max_price,
                        AVG(price_final/100.0) as avg_price,
                        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price_final/100.0) as median_price,
                        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY price_final/100.0) as q1_price,
                        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY price_final/100.0) as q3_price
                    FROM games 
                    WHERE type = 'game' AND price_final > 0
                ),
                review_stats AS (
                    SELECT 
                        MIN(positive_reviews + negative_reviews) as min_reviews,
                        MAX(positive_reviews + negative_reviews) as max_reviews,
                        AVG(positive_reviews + negative_reviews) as avg_reviews,
                        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY positive_reviews + negative_reviews) as median_reviews,
                        COUNT(CASE WHEN positive_reviews + negative_reviews = 0 THEN 1 END) as zero_reviews
                    FROM games 
                    WHERE type = 'game'
                ),
                platform_stats AS (
                    SELECT 
                        COUNT(CASE WHEN platforms_windows THEN 1 END) as windows_count,
                        COUNT(CASE WHEN platforms_mac THEN 1 END) as mac_count,
                        COUNT(CASE WHEN platforms_linux THEN 1 END) as linux_count,
                        COUNT(*) as total_games
                    FROM games 
                    WHERE type = 'game'
                )
                SELECT 
                    p.min_price, p.max_price, p.avg_price, p.median_price, p.q1_price, p.q3_price,
                    r.min_reviews, r.max_reviews, r.avg_reviews, r.median_reviews, r.zero_reviews,
                    pl.windows_count, pl.mac_count, pl.linux_count, pl.total_games
                FROM price_stats p, review_stats r, platform_stats pl;
            """)
            
            result = await session.execute(distribution_query)
            dist_data = dict(result.fetchone()._mapping)
            
            # åˆ†å¸ƒç•°å¸¸ã®æ¤œå‡º
            anomalies = []
            
            # ä¾¡æ ¼åˆ†å¸ƒã®ç•°å¸¸æ¤œå‡º
            if dist_data['max_price'] and dist_data['avg_price']:
                price_range = dist_data['max_price'] - dist_data['min_price']
                if price_range > 1000:  # $1000ä»¥ä¸Šã®ä¾¡æ ¼å¹…
                    anomalies.append(f"ä¾¡æ ¼å¹…ãŒç•°å¸¸ã«åºƒã„: ${dist_data['min_price']:.2f} - ${dist_data['max_price']:.2f}")
                
                # å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ–¹å¼ï¼‰
                if dist_data['q3_price'] and dist_data['q1_price']:
                    iqr = dist_data['q3_price'] - dist_data['q1_price']
                    upper_bound = dist_data['q3_price'] + 1.5 * iqr
                    if dist_data['max_price'] > upper_bound:
                        anomalies.append(f"ä¾¡æ ¼å¤–ã‚Œå€¤æ¤œå‡º: æœ€é«˜ä¾¡æ ¼${dist_data['max_price']:.2f}ãŒä¸Šé™${upper_bound:.2f}ã‚’è¶…é")
            
            # ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†å¸ƒã®ç•°å¸¸æ¤œå‡º
            if dist_data['zero_reviews'] and dist_data['total_games']:
                zero_review_ratio = dist_data['zero_reviews'] / dist_data['total_games']
                if zero_review_ratio > 0.8:  # 80%ä»¥ä¸ŠãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—
                    anomalies.append(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—ã‚²ãƒ¼ãƒ ãŒ{zero_review_ratio:.1%}ã¨é«˜æ¯”ç‡")
            
            # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ†å¸ƒã®ç•°å¸¸æ¤œå‡º
            if dist_data['total_games'] > 0:
                windows_ratio = dist_data['windows_count'] / dist_data['total_games']
                if windows_ratio < 0.5:  # Windowså¯¾å¿œç‡ãŒ50%æœªæº€
                    anomalies.append(f"Windowså¯¾å¿œç‡ãŒ{windows_ratio:.1%}ã¨ä½ã„")
            
            return {
                'distribution_metrics': dist_data,
                'anomalies_detected': anomalies,
                'check_timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def check_data_freshness_async(self, session: AsyncSession) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
        Returns:
            ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒã‚§ãƒƒã‚¯çµæœ
        """
        try:
            freshness_query = text("""
                SELECT 
                    COUNT(*) as total_games,
                    MIN(created_at) as oldest_record,
                    MAX(created_at) as newest_record,
                    COUNT(CASE WHEN created_at >= NOW() - INTERVAL '1 day' THEN 1 END) as records_last_24h,
                    COUNT(CASE WHEN created_at >= NOW() - INTERVAL '1 week' THEN 1 END) as records_last_week,
                    COUNT(CASE WHEN created_at >= NOW() - INTERVAL '1 month' THEN 1 END) as records_last_month
                FROM games 
                WHERE type = 'game';
            """)
            
            result = await session.execute(freshness_query)
            freshness_data = dict(result.fetchone()._mapping)
            
            # é®®åº¦è©•ä¾¡
            freshness_issues = []
            total_games = freshness_data['total_games']
            
            if total_games > 0:
                recent_ratio = freshness_data['records_last_week'] / total_games
                if recent_ratio < 0.1:  # æœ€è¿‘1é€±é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒ10%æœªæº€
                    freshness_issues.append(f"æœ€è¿‘1é€±é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒ{recent_ratio:.1%}ã¨å°‘ãªã„")
                
                daily_ratio = freshness_data['records_last_24h'] / total_games
                if daily_ratio == 0 and total_games > 100:  # å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ—¥æ¬¡æ›´æ–°ãªã—
                    freshness_issues.append("éå»24æ™‚é–“ã§æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚Œã¦ã„ãªã„")
            
            return {
                'freshness_metrics': freshness_data,
                'freshness_issues': freshness_issues,
                'check_timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def generate_quality_recommendations_async(self, session: AsyncSession) -> List[str]:
        """
        ãƒ‡ãƒ¼ã‚¿å“è³ªæ”¹å–„ææ¡ˆç”Ÿæˆï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
        Returns:
            æ”¹å–„ææ¡ˆã®ãƒªã‚¹ãƒˆ
        """
        recommendations = []
        
        try:
            # å„ç¨®å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚’å–å¾—
            tasks = [
                self.check_basic_data_quality_async(session),
                self.check_data_distribution_async(session),
                self.check_data_freshness_async(session)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            basic_quality, distribution, freshness = results
            
            # åŸºæœ¬å“è³ªã«åŸºã¥ãææ¡ˆ
            if not isinstance(basic_quality, Exception) and basic_quality.get('quality_score', 0) < 80:
                recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢ãŒ80%æœªæº€ã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦")
            
            if not isinstance(basic_quality, Exception) and basic_quality.get('issues_found'):
                if any("æ¬ æ" in issue for issue in basic_quality['issues_found']):
                    recommendations.append("æ¬ æãƒ‡ãƒ¼ã‚¿ã®è£œå®Œã¾ãŸã¯é™¤å¤–å‡¦ç†ã‚’å®Ÿè£…")
                if any("è² ã®" in issue for issue in basic_quality['issues_found']):
                    recommendations.append("ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚’å¼·åŒ–")
            
            # åˆ†å¸ƒã«åŸºã¥ãææ¡ˆ
            if not isinstance(distribution, Exception) and distribution.get('anomalies_detected'):
                recommendations.append("å¤–ã‚Œå€¤æ¤œå‡ºãƒ»é™¤å¤–æ©Ÿèƒ½ã‚’å°å…¥")
                recommendations.append("ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¼·åŒ–")
            
            # é®®åº¦ã«åŸºã¥ãææ¡ˆ
            if not isinstance(freshness, Exception) and freshness.get('freshness_issues'):
                recommendations.append("ãƒ‡ãƒ¼ã‚¿åé›†ã®è‡ªå‹•åŒ–ãƒ»ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°æ”¹å–„")
                recommendations.append("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã®æ¤œè¨")
            
            # ç·åˆçš„ãªææ¡ˆ
            recommendations.extend([
                "ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¨­ç½®",
                "ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½ã®å®Ÿè£…",
                "ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®šæœŸãƒ¬ãƒãƒ¼ãƒˆåŒ–"
            ])
            
        except Exception as e:
            self.logger.error(f"å“è³ªæ”¹å–„ææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return recommendations

    async def generate_comprehensive_quality_report_async(self, session: AsyncSession) -> Dict[str, Any]:
        """
        åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
        Returns:
            åŒ…æ‹¬çš„å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
        """
        try:
            # å„ç¨®å“è³ªåˆ†æã‚’ä¸¦è¡Œå®Ÿè¡Œ
            tasks = [
                self.check_basic_data_quality_async(session),
                self.check_data_distribution_async(session),
                self.check_data_freshness_async(session),
                self.generate_quality_recommendations_async(session)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # çµæœã®çµ±åˆ
            report = {
                'report_id': f"data_quality_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'generated_at': datetime.now().isoformat(),
                'basic_quality': results[0] if not isinstance(results[0], Exception) else {},
                'distribution_analysis': results[1] if not isinstance(results[1], Exception) else {},
                'freshness_analysis': results[2] if not isinstance(results[2], Exception) else {},
                'recommendations': results[3] if not isinstance(results[3], Exception) else [],
                'report_status': 'completed',
                'error_count': sum(1 for r in results if isinstance(r, Exception))
            }
            
            return report
            
        except Exception as e:
            self.logger.error(f"åŒ…æ‹¬å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'report_id': f"data_quality_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'generated_at': datetime.now().isoformat(),
                'error': str(e),
                'report_status': 'failed'
            }

    def check_basic_quality_sync(self) -> Dict[str, Any]:
        """
        åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆåŒæœŸç‰ˆãƒ»äº’æ›æ€§ã®ãŸã‚ï¼‰
        
        Returns:
            åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯çµæœ
        """
        try:
            with self.engine.connect() as conn:
                basic_query = text("""
                    SELECT 
                        COUNT(*) as total_games,
                        COUNT(CASE WHEN name IS NULL OR name = '' THEN 1 END) as missing_names,
                        COUNT(CASE WHEN genres IS NULL THEN 1 END) as missing_genres,
                        COUNT(CASE WHEN price_final IS NULL THEN 1 END) as missing_prices
                    FROM games 
                    WHERE type = 'game';
                """)
                
                result = conn.execute(basic_query)
                data = dict(result.fetchone()._mapping)
                
                # å“è³ªã‚¹ã‚³ã‚¢ç°¡æ˜“è¨ˆç®—
                total = data['total_games']
                if total > 0:
                    missing_ratio = (data['missing_names'] + data['missing_genres'] + data['missing_prices']) / (total * 3)
                    quality_score = (1 - missing_ratio) * 100
                else:
                    quality_score = 0
                
                return {
                    'quality_metrics': data,
                    'quality_score': round(quality_score, 1),
                    'check_timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            self.logger.error(f"åŒæœŸå“è³ªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {}


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨ã®éåŒæœŸãƒ¡ã‚¤ãƒ³é–¢æ•°
async def main_async():
    """éåŒæœŸãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    checker = DataQualityChecker()
    
    if get_db_session:
        async with get_db_session() as session:
            print("ğŸ” ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
            report = await checker.generate_comprehensive_quality_report_async(session)
            
            print("ğŸ“Š Steam ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ")
            print("=" * 50)
            
            if report.get('basic_quality', {}).get('quality_metrics'):
                metrics = report['basic_quality']['quality_metrics']
                score = report['basic_quality']['quality_score']
                print(f"\nğŸ“ˆ å“è³ªã‚¹ã‚³ã‚¢: {score}%")
                print(f"  ç·ã‚²ãƒ¼ãƒ æ•°: {metrics['total_games']:,}")
                print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯IDæ•°: {metrics['unique_app_ids']:,}")
                if metrics['missing_names'] > 0:
                    print(f"  ã‚²ãƒ¼ãƒ åæ¬ æ: {metrics['missing_names']:,}ä»¶")
                if metrics['missing_genres'] > 0:
                    print(f"  ã‚¸ãƒ£ãƒ³ãƒ«æ¬ æ: {metrics['missing_genres']:,}ä»¶")
            
            if report.get('basic_quality', {}).get('issues_found'):
                print("\nâš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
                for issue in report['basic_quality']['issues_found']:
                    print(f"  â€¢ {issue}")
            
            if report.get('distribution_analysis', {}).get('anomalies_detected'):
                print("\nğŸš¨ åˆ†å¸ƒç•°å¸¸:")
                for anomaly in report['distribution_analysis']['anomalies_detected']:
                    print(f"  â€¢ {anomaly}")
            
            if report.get('freshness_analysis', {}).get('freshness_issues'):
                print("\nâ° é®®åº¦å•é¡Œ:")
                for issue in report['freshness_analysis']['freshness_issues']:
                    print(f"  â€¢ {issue}")
            
            if report.get('recommendations'):
                print("\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
                for i, rec in enumerate(report['recommendations'], 1):
                    print(f"  {i}. {rec}")
            
            print(f"\nğŸ“… ãƒã‚§ãƒƒã‚¯æ—¥æ™‚: {report['generated_at']}")
            print(f"ğŸ¯ ãƒ¬ãƒãƒ¼ãƒˆçŠ¶æ³: {report['report_status']}")
    else:
        print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŒæœŸç‰ˆãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        result = checker.check_basic_quality_sync()
        print("ğŸ“Š åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯:")
        print(f"å“è³ªã‚¹ã‚³ã‚¢: {result.get('quality_score', 0)}%")


if __name__ == "__main__":
    asyncio.run(main_async())